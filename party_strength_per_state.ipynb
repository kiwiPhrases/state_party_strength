{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Party Strength\n",
    "\n",
    "There seems to be no panel dataset of party strength in each state so here I attempt to scrape results from Wikipedia. It's a start and likely also the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import us\n",
    "\n",
    "data_path = \"C:/Users/SpiffyApple/Documents/USC/RaphaelBostic/policy_diffusion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining some preliminary functions: \n",
    "def fetch_website(url):\n",
    "    \"\"\"\n",
    "    To hide that the scraping is being done via Python, I change the user-agent to a Firefox\n",
    "    browser so that the website believes it is a chrome browser accessing them. Hope it works.\n",
    "    \"\"\"\n",
    "    user_agent={'User-agent':'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.18 Safari/537.36'}\n",
    "    r=requests.get(url, headers=user_agent)\n",
    "    try:\n",
    "        #print(\"Accessed and downloaded URL data\")\n",
    "        return(r.content)\n",
    "    except ConnectionError:\n",
    "        print(\"Skipping this url\")\n",
    "        return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##get US states to loop over\n",
    "us_states = [state.name for state in us.STATES if state.name != \"District of Columbia\"]\n",
    "us_states.append(\"Washington, D.C.\") #fix a little wikipedia issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##fwtch wiki data and record ones that don't have it\n",
    "out_dict = {}\n",
    "no_wiki = []\n",
    "missing_text = \"Wikipedia does not have an article with this exact name.\"\n",
    "url_base = \"https://en.wikipedia.org/wiki/Political_party_strength_in_\"\n",
    "wiki_urls = [url_base + re.sub(\" \", \"_\",state) for state in us_states]\n",
    "\n",
    "for state in us_states:\n",
    "    out_dict[state] = bs(fetch_website(url_base + re.sub(\" \", \"_\",state)), 'lxml')\n",
    "    if missing_text in out_dict[state].getText():\n",
    "        no_wiki.append(state)\n",
    "        out_dict[state] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_wiki "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the desired tables\n",
    "This is simply done by looking at which tables on the corresponding Wikipedia page contain the year 2014 since that's the year most other datasets do have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states with wikipedia table for party strength: 51\n"
     ]
    }
   ],
   "source": [
    "#usually there are multiple tables. Pick out ones that contain 2014\n",
    "data_dict = {}\n",
    "for state in us_states:\n",
    "    found_tables = out_dict[state].findAll(\"table\", class_='wikitable')\n",
    "    for table in found_tables:\n",
    "        if \"2014\" in table.getText():\n",
    "            data_dict[state] = table\n",
    "            \n",
    "#check how many states had a table with '2014' in it\n",
    "print(\"Number of states with wikipedia table for party strength: %d\" %len(data_dict.keys()))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the tables into Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## corresponding functiosn:\n",
    "def pre_process_table(table):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        1. table - a bs4 element that contains the desired table: ie <table> ... </table>\n",
    "    OUTPUT:\n",
    "        a tuple of: \n",
    "            1. rows - a list of table rows ie: list of <tr>...</tr> elements\n",
    "            2. num_rows - number of rows in the table\n",
    "            3. num_cols - number of columns in the table\n",
    "    Options:\n",
    "        include_td_head_count - whether to use only th or th and td to count number of columns (default: False)\n",
    "    \"\"\"\n",
    "    rows = [x for x in table.find_all('tr')]\n",
    "\n",
    "    num_rows = len(rows)\n",
    "    \n",
    "    num_cols = max([len(x.find_all(['th','td'])) for x in rows])\n",
    "\n",
    "    ##lets make col_num counter more complicated to account for colspans in headers. \n",
    "    header_rows_set = [x.find_all(['th', 'td']) for x in rows if len(x.find_all(['th', 'td']))>num_cols/2]\n",
    "    \n",
    "    num_cols_set = []\n",
    "\n",
    "    for header_rows in header_rows_set:\n",
    "        num_cols = 0\n",
    "        for cell in header_rows:\n",
    "            row_span, col_span = get_spans(cell)\n",
    "            num_cols+=len([cell.getText()]*col_span)\n",
    "            \n",
    "        num_cols_set.append(num_cols)\n",
    "    \n",
    "    num_cols = max(num_cols_set)\n",
    "    #print(num_cols)\n",
    "    \n",
    "    return (rows, num_rows, num_cols)\n",
    "\n",
    "\n",
    "def get_spans(cell):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "            1. cell - a <td>...</td> or <th>...</th> element that contains a table cell entry\n",
    "        OUTPUT:\n",
    "            1. a tuple with the cell's row and col spans\n",
    "        \"\"\"\n",
    "        if cell.has_attr('rowspan'):\n",
    "            rep_row = int(cell.attrs['rowspan'])\n",
    "        else: # ~cell.has_attr('rowspan'):\n",
    "            rep_row = 1\n",
    "        if cell.has_attr('colspan'):\n",
    "            rep_col = int(cell.attrs['colspan'])\n",
    "        else: # ~cell.has_attr('colspan'):\n",
    "            rep_col = 1 \n",
    "        \n",
    "        return (rep_row, rep_col)\n",
    " \n",
    "def process_rows(rows, num_rows, num_cols):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        1. rows - a list of table rows ie <tr>...</tr> elements\n",
    "    OUTPUT:\n",
    "        1. data - a Pandas dataframe with the html data in it\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(np.ones((num_rows, num_cols))*np.nan)\n",
    "    for i, row in enumerate(rows):\n",
    "        try:\n",
    "            col_stat = data.iloc[i,:][data.iloc[i,:].isnull()].index[0]\n",
    "        except IndexError:\n",
    "            print(\"Error at row %d\" %i, row, \"\\nParser may have failed to acquire correct number of columns. Num of columns: %d\" %num_cols)\n",
    "            print(\"Failed to locate starting point in above row. Subsequent rows are likely to be erronously parsed\")\n",
    "            \n",
    "        for j, cell in enumerate(row.find_all(['td', 'th'])):\n",
    "            rep_row, rep_col = get_spans(cell)\n",
    "\n",
    "            #print(\"cols {0} to {1} with rep_col={2}\".format(col_stat, col_stat+rep_col, rep_col))\n",
    "            #print(\"\\trows {0} to {1} with rep_row={2}\".format(i, i+rep_row, rep_row))\n",
    "\n",
    "            #find first non-na col and fill that one\n",
    "            while any(data.iloc[i,col_stat:col_stat+rep_col].notnull()):\n",
    "                col_stat+=1\n",
    "\n",
    "            data.iloc[i:i+rep_row,col_stat:col_stat+rep_col] = cell.getText()\n",
    "            if col_stat<data.shape[1]-1:\n",
    "                col_stat+=rep_col\n",
    "\n",
    "    return data\n",
    "\n",
    "def main(table):\n",
    "    rows, num_rows, num_cols = pre_process_table(table)\n",
    "    df = process_rows(rows, num_rows, num_cols)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## loop through the ditionary:\n",
    "df_dict_origin = {}\n",
    "\n",
    "for state in us_states:\n",
    "    df_dict_origin[state] = main(data_dict[state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Clean and combine the 51 data tables\n",
    "First, perhaps make each datatable into an indexed frame and then work from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dict = df_dict_origin.copy()\n",
    "\n",
    "##it may actually make sense to make columns from the second to last row, then drop duplicates if necessary, set index, etc\n",
    "for state in us_states:\n",
    "    df_dict[state].columns = df_dict[state].iloc[-1].str.lower() + \":\" + df_dict[state].iloc[-2].str.lower()\n",
    "    df_dict[state].columns.name = None\n",
    "    \n",
    "    #remove duplicated columns:\n",
    "    df_dict[state] = df_dict[state].loc[:,~df_dict[state].columns.duplicated()]\n",
    "    \n",
    "    #set the index, clean it up, assign it the right numeric type, subset\n",
    "    df_dict[state].set_index('year:year', inplace=True)\n",
    "    df_dict[state] = df_dict[state][df_dict[state].index.str.contains(\"\\d\")]\n",
    "    df_dict[state].index.name = 'year'\n",
    "    \n",
    "    df_dict[state].index = df_dict[state].index.str.extract(\"(\\d+)\", expand=False)\n",
    "    df_dict[state].index = df_dict[state].index.astype(np.int64)\n",
    "    df_dict[state] = df_dict[state].loc[df_dict[state].index>=1980]\n",
    "    \n",
    "    df_dict[state] = df_dict[state].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try to fix the columns -- this cell may need to be run multiple times -- not sure why\n",
    "for state in us_states:\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"^gov$\", \"governor\")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"general house assembly\", 'state legislature')\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"general court\", 'state legislature')\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"general assembly\", \"state legislature\")    \n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"/constitutional\", \"\")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"mayor\", 'governor')   \n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\" assem$\", ' house')\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\" assembly$\", ' house')\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"district \\d$\", \"\")    \n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"representatives\", \"house\")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"legislative assembly\", \"state legislature\")\n",
    "    \n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"united states\", 'us')\n",
    "    \n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"class i$\", \"class 1\")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"class ii$\", \"class 2\")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"class iii$\", \"class 3\")\n",
    "    \n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"senate\", \"sen\")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"senator\", 'sen')\n",
    "    \n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"^us |:us| u\\.s\\.\", \" \")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\":state\", \" \")\n",
    "    #df_dict[state].columns = df_dict[state].columns.str.replace(\"lieutenant\", 'lt')\n",
    "    #df_dict[state].columns = df_dict[state].columns.str.replace(\"(?:s)\", \"\\1\")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"  \", \" \")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"executive offices?:\", \"\")\n",
    "    #df_dict[state].columns = df_dict[state].columns.str.replace(\"^electoral college votes:\", \"\")\n",
    "\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"\\(|\\)|:|\\\\n\", \" \")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"\\.\", \"\")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"\\scollege([\\s\\w]+)\", \"\")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"\\sus\\s\", \" \")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.replace(\"state legislature legislature\", \"state legislature house\")\n",
    "    df_dict[state].columns = df_dict[state].columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dict['Washington, D.C.'].rename(columns = {'congress house delegate':\"congress house\",\n",
    "                                              \"congress shadow sen seat 1\":\"congress sen class 1\",\n",
    "                                             'congress shadow sen seat 2':\"congress sen class 2\",\n",
    "                                             'presidential electoral':\"electoral\"}, inplace=True)\n",
    "df_dict['Washington, D.C.'].drop(\"congress shadow representative\", axis=1, inplace=True)\n",
    "df_dict['Maine'].drop(\"congress former house districts\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##some columns are now duplicated, need to rid myself of them. Similar with the senate columns.\n",
    "for state in us_states:\n",
    "    bool_arr = df_dict[state].columns.str.contains(\"congress house\")\n",
    "    if np.sum(bool_arr)>1:\n",
    "        temp = df_dict[state].loc[:,df_dict[state].columns.str.contains(\"congress house\")].sum(axis=1)\n",
    "        df_dict[state] = df_dict[state].loc[:,~bool_arr]\n",
    "        df_dict[state]['congress house'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama\n",
      " 7\n",
      "Alaska\n",
      " 7\n",
      "Arizona\n",
      " 7\n",
      "Arkansas\n",
      " 7\n",
      "California\n",
      " 7\n",
      "Colorado\n",
      " 7\n",
      "Connecticut\n",
      " 7\n",
      "Delaware\n",
      " 7\n",
      "Florida\n",
      " 7\n",
      "Georgia\n",
      " 7\n",
      "Hawaii\n",
      " 7\n",
      "Idaho\n",
      " 7\n",
      "Illinois\n",
      " 7\n",
      "Indiana\n",
      " 7\n",
      "Iowa\n",
      " 7\n",
      "Kansas\n",
      " 7\n",
      "Kentucky\n",
      " 7\n",
      "Louisiana\n",
      " 7\n",
      "Maine\n",
      " 7\n",
      "Maryland\n",
      " 7\n",
      "Massachusetts\n",
      " 6\n",
      "Michigan\n",
      " 7\n",
      "Minnesota\n",
      " 7\n",
      "Mississippi\n",
      " 7\n",
      "Missouri\n",
      " 7\n",
      "Montana\n",
      " 7\n",
      "Nebraska\n",
      " 6\n",
      "Nevada\n",
      " 7\n",
      "New Hampshire\n",
      " 7\n",
      "New Jersey\n",
      " 7\n",
      "New Mexico\n",
      " 7\n",
      "New York\n",
      " 7\n",
      "North Carolina\n",
      " 7\n",
      "North Dakota\n",
      " 7\n",
      "Ohio\n",
      " 7\n",
      "Oklahoma\n",
      " 7\n",
      "Oregon\n",
      " 7\n",
      "Pennsylvania\n",
      " 7\n",
      "Rhode Island\n",
      " 7\n",
      "South Carolina\n",
      " 7\n",
      "South Dakota\n",
      " 7\n",
      "Tennessee\n",
      " 7\n",
      "Texas\n",
      " 7\n",
      "Utah\n",
      " 7\n",
      "Vermont\n",
      " 7\n",
      "Virginia\n",
      " 7\n",
      "Washington\n",
      " 7\n",
      "West Virginia\n",
      " 7\n",
      "Wisconsin\n",
      " 7\n",
      "Wyoming\n",
      " 7\n",
      "Washington, D.C.\n",
      " 5\n"
     ]
    }
   ],
   "source": [
    "for state in us_states:\n",
    "    print(state+\"\\n\",df_dict[state].loc[:,df_dict[state].columns.str.contains('^governor|house|sen|electoral')].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "combnd = pd.concat([df_dict[state].loc[:,df_dict[state].columns.str.contains('^governor|house|sen|electoral')] for state in us_states], keys=us_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>congress house</th>\n",
       "      <th>congress sen class 1</th>\n",
       "      <th>congress sen class 2</th>\n",
       "      <th>congress sen class 3</th>\n",
       "      <th>electoral</th>\n",
       "      <th>governor</th>\n",
       "      <th>state legislature house</th>\n",
       "      <th>state legislature sen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n",
       "      <th>1980</th>\n",
       "      <td>4D, 3R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Howell Heflin (D)</td>\n",
       "      <td>Donald W. Stewart (D)</td>\n",
       "      <td>Ronald Reagan and George H. W. Bush (R) Y</td>\n",
       "      <td>Fob James (D)</td>\n",
       "      <td>101D, 4R</td>\n",
       "      <td>35D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>4D, 3R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Howell Heflin (D)</td>\n",
       "      <td>Jeremiah Denton (R)</td>\n",
       "      <td>Ronald Reagan and George H. W. Bush (R) Y</td>\n",
       "      <td>Fob James (D)</td>\n",
       "      <td>101D, 4R</td>\n",
       "      <td>35D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>4D, 3R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Howell Heflin (D)</td>\n",
       "      <td>Jeremiah Denton (R)</td>\n",
       "      <td>Ronald Reagan and George H. W. Bush (R) Y</td>\n",
       "      <td>Fob James (D)</td>\n",
       "      <td>101D, 4R</td>\n",
       "      <td>35D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>5D, 2R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Howell Heflin (D)</td>\n",
       "      <td>Jeremiah Denton (R)</td>\n",
       "      <td>Ronald Reagan and George H. W. Bush (R) Y</td>\n",
       "      <td>George Wallace (D)</td>\n",
       "      <td>97D, 8R</td>\n",
       "      <td>32D, 3R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>5D, 2R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Howell Heflin (D)</td>\n",
       "      <td>Jeremiah Denton (R)</td>\n",
       "      <td>Ronald Reagan and George H. W. Bush (R) Y</td>\n",
       "      <td>George Wallace (D)</td>\n",
       "      <td>87D, 18R</td>\n",
       "      <td>29D, 3R, 3I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             congress house congress sen class 1 congress sen class 2  \\\n",
       "        year                                                            \n",
       "Alabama 1980         4D, 3R                  NaN    Howell Heflin (D)   \n",
       "        1981         4D, 3R                  NaN    Howell Heflin (D)   \n",
       "        1982         4D, 3R                  NaN    Howell Heflin (D)   \n",
       "        1983         5D, 2R                  NaN    Howell Heflin (D)   \n",
       "        1984         5D, 2R                  NaN    Howell Heflin (D)   \n",
       "\n",
       "               congress sen class 3  \\\n",
       "        year                          \n",
       "Alabama 1980  Donald W. Stewart (D)   \n",
       "        1981    Jeremiah Denton (R)   \n",
       "        1982    Jeremiah Denton (R)   \n",
       "        1983    Jeremiah Denton (R)   \n",
       "        1984    Jeremiah Denton (R)   \n",
       "\n",
       "                                              electoral            governor  \\\n",
       "        year                                                                  \n",
       "Alabama 1980  Ronald Reagan and George H. W. Bush (R) Y       Fob James (D)   \n",
       "        1981  Ronald Reagan and George H. W. Bush (R) Y       Fob James (D)   \n",
       "        1982  Ronald Reagan and George H. W. Bush (R) Y       Fob James (D)   \n",
       "        1983  Ronald Reagan and George H. W. Bush (R) Y  George Wallace (D)   \n",
       "        1984  Ronald Reagan and George H. W. Bush (R) Y  George Wallace (D)   \n",
       "\n",
       "             state legislature house state legislature sen  \n",
       "        year                                                \n",
       "Alabama 1980                101D, 4R                   35D  \n",
       "        1981                101D, 4R                   35D  \n",
       "        1982                101D, 4R                   35D  \n",
       "        1983                 97D, 8R               32D, 3R  \n",
       "        1984                87D, 18R           29D, 3R, 3I  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combnd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combnd.to_csv(\"/\".join([data_path, \"states_party_strength.csv\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
